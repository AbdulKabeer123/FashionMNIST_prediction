{"cells":[{"source":"![Clothing Classifier Model](Clothing%20Classifier%20Model.png)\n","metadata":{},"id":"06e96af4-1831-41d9-a3d7-76004d4f01a9","cell_type":"markdown"},{"source":"Fashion Forward is a new AI-based e-commerce clothing retailer.\nThey want to use image classification to automatically categorize new product listings, making it easier for customers to find what they're looking for. It will also assist in inventory management by quickly sorting items.\n\nAs a data scientist tasked with implementing a garment classifier, your primary objective is to develop a machine learning model capable of accurately categorizing images of clothing items into distinct garment types such as shirts, trousers, shoes, etc.\n","metadata":{"tags":[]},"id":"35d4e17b-eeb6-40dd-a140-7b949390e115","cell_type":"markdown","attachments":{}},{"source":"# Run the cells below first","metadata":{"executionCancelledAt":null,"executionTime":13,"lastExecutedAt":1708370476706,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run the cells below first"},"id":"faf2e25e-6c2f-450d-95c1-e03d470cb2f1","cell_type":"code","execution_count":16,"outputs":[]},{"source":"!pip install torchmetrics","metadata":{"executionCancelledAt":null,"executionTime":5409,"lastExecutedAt":1708370482115,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install torchmetrics","outputsMetadata":{"0":{"height":424,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"id":"4de0b0ff-a211-41be-b90e-165e6038c9d7","cell_type":"code","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: torchmetrics in /home/repl/.local/lib/python3.8/site-packages (1.3.1)\nRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.23.2)\nRequirement already satisfied: packaging>17.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /home/repl/.local/lib/python3.8/site-packages (from torchmetrics) (0.10.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.9.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (65.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>17.1->torchmetrics) (3.0.9)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.10.3.66)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\nRequirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->torchmetrics) (0.38.4)\n"}]},{"source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall\nfrom torchvision import datasets\nimport torchvision.transforms as transforms","id":"145bbc0f-4d15-4e7b-b796-5ec0d9ab7702","cell_type":"code","outputs":[],"metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1708370482165,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall\nfrom torchvision import datasets\nimport torchvision.transforms as transforms"},"execution_count":18},{"source":"# Load datasets\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())","id":"35ddad8f-fa43-4bb3-894b-afef8d0bfd59","cell_type":"code","outputs":[],"metadata":{"executionCancelledAt":null,"executionTime":64,"lastExecutedAt":1708370482229,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load datasets\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())","outputsMetadata":{"0":{"height":97,"type":"stream"},"2":{"height":157,"type":"stream"},"4":{"height":157,"type":"stream"},"6":{"height":157,"type":"stream"},"8":{"height":77,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"execution_count":19},{"source":"classes = train_data.classes\nnum_classes = len(train_data.classes)","id":"e5d01322-e517-44b8-a68f-1ff0e291418f","cell_type":"code","outputs":[],"metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1708370482281,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"classes = train_data.classes\nnum_classes = len(train_data.classes)"},"execution_count":20},{"source":"import numpy as np\nimport torch\nfrom torchvision import datasets, transforms\n\n# Load datasets\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n\n# Convert PyTorch tensor to NumPy array\nimages = train_data.data.numpy()\nlabels = np.array(train_data.targets)\n\n# Display head of the data\nhead_images = images[:5]\nhead_labels = labels[:5]\n\nprint(\"Head of the data:\")\nprint(\"Images shape:\", head_images.shape)\nprint(\"Labels:\", head_labels)\n\n# Display tail of the data\ntail_images = images[-5:]\ntail_labels = labels[-5:]\n\nprint(\"\\nTail of the data:\")\nprint(\"Images shape:\", tail_images.shape)\nprint(\"Labels:\", tail_labels)\n","metadata":{"executionCancelledAt":null,"executionTime":63,"lastExecutedAt":1708370482345,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import numpy as np\nimport torch\nfrom torchvision import datasets, transforms\n\n# Load datasets\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n\n# Convert PyTorch tensor to NumPy array\nimages = train_data.data.numpy()\nlabels = np.array(train_data.targets)\n\n# Display head of the data\nhead_images = images[:5]\nhead_labels = labels[:5]\n\nprint(\"Head of the data:\")\nprint(\"Images shape:\", head_images.shape)\nprint(\"Labels:\", head_labels)\n\n# Display tail of the data\ntail_images = images[-5:]\ntail_labels = labels[-5:]\n\nprint(\"\\nTail of the data:\")\nprint(\"Images shape:\", tail_images.shape)\nprint(\"Labels:\", tail_labels)\n","outputsMetadata":{"0":{"height":157,"type":"stream"}}},"cell_type":"code","id":"b7e63d00-3245-42eb-89b3-f1239a80a9ca","outputs":[{"output_type":"stream","name":"stdout","text":"Head of the data:\nImages shape: (5, 28, 28)\nLabels: [9 0 0 3 0]\n\nTail of the data:\nImages shape: (5, 28, 28)\nLabels: [5 1 3 0 5]\n"}],"execution_count":21},{"source":"from torchvision import datasets, transforms\n\n# Load FashionMNIST dataset\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n\n# Get the list of classes\nclasses = train_data.classes\n\n# Print the list of classes\nprint(\"Classes in the FashionMNIST dataset:\")\nfor idx, class_name in enumerate(classes):\n    print(f\"{idx}: {class_name}\")\n","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1708370482398,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from torchvision import datasets, transforms\n\n# Load FashionMNIST dataset\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n\n# Get the list of classes\nclasses = train_data.classes\n\n# Print the list of classes\nprint(\"Classes in the FashionMNIST dataset:\")\nfor idx, class_name in enumerate(classes):\n    print(f\"{idx}: {class_name}\")\n","outputsMetadata":{"0":{"height":237,"type":"stream"}}},"cell_type":"code","id":"6e7d0a7d-250a-4499-8cc5-f7d62bd021ff","outputs":[{"output_type":"stream","name":"stdout","text":"Classes in the FashionMNIST dataset:\n0: T-shirt/top\n1: Trouser\n2: Pullover\n3: Dress\n4: Coat\n5: Sandal\n6: Shirt\n7: Sneaker\n8: Bag\n9: Ankle boot\n"}],"execution_count":22},{"source":"num_input_channels = 1\nnum_output_channels = 16\nimage_size = train_data[0][0].shape[1]","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1708370482445,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"num_input_channels = 1\nnum_output_channels = 16\nimage_size = train_data[0][0].shape[1]"},"cell_type":"code","id":"3e64a73a-82bb-437a-aaf2-41241df927e7","outputs":[],"execution_count":23},{"source":"class MultiClassImageClassifier(nn.Module):\n  \n    # Define the init method\n    def __init__(self, num_classes):\n        super(MultiClassImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_input_channels, num_output_channels, kernel_size=3, stride=1, padding=1)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.flatten = nn.Flatten()\n\n        # Create a fully connected layer\n        self.fc = nn.Linear(num_output_channels * (image_size//2)**2, num_classes)\n        \n    def forward(self, x):\n        # Pass inputs through each layer\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.flatten(x)\n        x = self.fc(x)\n        return x","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1708370482497,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"class MultiClassImageClassifier(nn.Module):\n  \n    # Define the init method\n    def __init__(self, num_classes):\n        super(MultiClassImageClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(num_input_channels, num_output_channels, kernel_size=3, stride=1, padding=1)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.flatten = nn.Flatten()\n\n        # Create a fully connected layer\n        self.fc = nn.Linear(num_output_channels * (image_size//2)**2, num_classes)\n        \n    def forward(self, x):\n        # Pass inputs through each layer\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.flatten(x)\n        x = self.fc(x)\n        return x"},"cell_type":"code","id":"df78dc77-2a51-400d-aee0-4792f1ddfb9c","outputs":[],"execution_count":24},{"source":"# Define the training set DataLoader\ndataloader_train = DataLoader(\n    train_data,\n    batch_size=10,\n    shuffle=True,\n)\n","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1708370482553,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the training set DataLoader\ndataloader_train = DataLoader(\n    train_data,\n    batch_size=10,\n    shuffle=True,\n)\n"},"cell_type":"code","id":"8940dcd5-0b6c-4797-9450-63accfdde819","outputs":[],"execution_count":25},{"source":"# Define training function\ndef train_model(optimizer, net, num_epochs):\n    num_processed = 0\n    criterion = nn.CrossEntropyLoss()\n    for epoch in range(num_epochs):\n        running_loss = 0\n        num_processed = 0\n        for features, labels in dataloader_train:\n            optimizer.zero_grad()\n            outputs = net(features)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            num_processed += len(labels)\n        print(f'epoch {epoch}, loss: {running_loss / num_processed}')\n        \n    train_loss = running_loss / len(dataloader_train)\n","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1708370482605,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define training function\ndef train_model(optimizer, net, num_epochs):\n    num_processed = 0\n    criterion = nn.CrossEntropyLoss()\n    for epoch in range(num_epochs):\n        running_loss = 0\n        num_processed = 0\n        for features, labels in dataloader_train:\n            optimizer.zero_grad()\n            outputs = net(features)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            num_processed += len(labels)\n        print(f'epoch {epoch}, loss: {running_loss / num_processed}')\n        \n    train_loss = running_loss / len(dataloader_train)\n"},"cell_type":"code","id":"e95c498b-2650-42f9-91f4-eb769180686a","outputs":[],"execution_count":26},{"source":"net = MultiClassImageClassifier(num_classes)\noptimizer = optim.Adam(net.parameters(), lr=0.01)\n\ntrain_model(\n    optimizer=optimizer,\n    net=net,\n    num_epochs=1,\n)\n","metadata":{"executionCancelledAt":null,"executionTime":12682,"lastExecutedAt":1708370495288,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"net = MultiClassImageClassifier(num_classes)\noptimizer = optim.Adam(net.parameters(), lr=0.01)\n\ntrain_model(\n    optimizer=optimizer,\n    net=net,\n    num_epochs=1,\n)\n","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"cell_type":"code","id":"0024d1bc-0bf3-4259-90c7-7fd0d399e4d4","outputs":[{"output_type":"stream","name":"stdout","text":"epoch 0, loss: 0.040509520426933884\n"}],"execution_count":27},{"source":"#Test set Loader\ndataloader_test = DataLoader(\n    test_data,\n    batch_size=10,\n    shuffle=False,\n)","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1708370495337,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Test set Loader\ndataloader_test = DataLoader(\n    test_data,\n    batch_size=10,\n    shuffle=False,\n)"},"cell_type":"code","id":"c8d86cdf-4330-44f5-abd9-badd7bd8ab92","outputs":[],"execution_count":28},{"source":"#Now calculating evauation metrics\naccuracy_metric = Accuracy(task='multiclass', num_classes=num_classes)\nprecision_metric = Precision(task='multiclass', num_classes=num_classes, average=None)\nrecall_metric = Recall(task='multiclass', num_classes=num_classes, average=None)","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1708370495385,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Now calculating evauation metrics\naccuracy_metric = Accuracy(task='multiclass', num_classes=num_classes)\nprecision_metric = Precision(task='multiclass', num_classes=num_classes, average=None)\nrecall_metric = Recall(task='multiclass', num_classes=num_classes, average=None)"},"cell_type":"code","id":"c93fa82a-8496-4b98-b6a5-014434562804","outputs":[],"execution_count":29},{"source":"#model runing on test set\nnet.eval()\npredicted = []\nfor i, (features, labels) in enumerate(dataloader_test):\n    output = net.forward(features.reshape(-1, 1, image_size, image_size))\n    cat = torch.argmax(output, dim=-1)\n    predicted.extend(cat.tolist())\n    accuracy_metric(cat, labels)\n    precision_metric(cat, labels)\n    recall_metric(cat, labels)\n\naccuracy = accuracy_metric.compute().item()\nprecision = precision_metric.compute().tolist()\nrecall = recall_metric.compute().tolist()\nprint('Accuracy: (per_class)', accuracy)\nprint('Precision (per class):', precision)\nprint('Recall (per_class)', recall)","metadata":{"executionCancelledAt":null,"executionTime":2130,"lastExecutedAt":1708370497515,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#model runing on test set\nnet.eval()\npredicted = []\nfor i, (features, labels) in enumerate(dataloader_test):\n    output = net.forward(features.reshape(-1, 1, image_size, image_size))\n    cat = torch.argmax(output, dim=-1)\n    predicted.extend(cat.tolist())\n    accuracy_metric(cat, labels)\n    precision_metric(cat, labels)\n    recall_metric(cat, labels)\n\naccuracy = accuracy_metric.compute().item()\nprecision = precision_metric.compute().tolist()\nrecall = recall_metric.compute().tolist()\nprint('Accuracy: (per_class)', accuracy)\nprint('Precision (per class):', precision)\nprint('Recall (per_class)', recall)","outputsMetadata":{"0":{"height":117,"type":"stream"}}},"cell_type":"code","id":"da87aaa4-b8fc-42da-9650-e0b4f057f091","outputs":[{"output_type":"stream","name":"stdout","text":"Accuracy: (per_class) 0.8673999905586243\nPrecision (per class): [0.7861060500144958, 0.9809428453445435, 0.8331527709960938, 0.7729116082191467, 0.7983281016349792, 0.9706477522850037, 0.7407407164573669, 0.9783352613449097, 0.9461020231246948, 0.8714788556098938]\nRecall (per_class) [0.8600000143051147, 0.9779999852180481, 0.7689999938011169, 0.953000009059906, 0.7639999985694885, 0.9589999914169312, 0.5600000023841858, 0.8579999804496765, 0.9829999804496765, 0.9900000095367432]\n"}],"execution_count":30}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}